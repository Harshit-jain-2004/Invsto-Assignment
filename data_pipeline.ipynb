{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dabefb7-f9d1-4847-b336-d4913d3ba9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data integrity is valid. No missing values or type inconsistencies detected.\n",
      "\n",
      "\n",
      "           Date        Open        High         Low       Close   Adj Close  \\\n",
      "0    2023-01-03   89.589996   91.050003   88.519997   89.120003   89.120003   \n",
      "1    2023-01-04   90.349998   90.650002   87.269997   88.080002   88.080002   \n",
      "2    2023-01-05   87.470001   87.570000   85.900002   86.199997   86.199997   \n",
      "3    2023-01-06   86.790001   87.690002   84.860001   87.339996   87.339996   \n",
      "4    2023-01-09   88.360001   90.050003   87.860001   88.019997   88.019997   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "245  2023-12-22  140.770004  141.990005  140.710007  141.490005  141.490005   \n",
      "246  2023-12-26  141.589996  142.679993  141.190002  141.520004  141.520004   \n",
      "247  2023-12-27  141.589996  142.080002  139.889999  140.369995  140.369995   \n",
      "248  2023-12-28  140.779999  141.139999  139.750000  140.229996  140.229996   \n",
      "249  2023-12-29  139.630005  140.360001  138.779999  139.690002  139.690002   \n",
      "\n",
      "       Volume  \n",
      "0    28131200  \n",
      "1    34854800  \n",
      "2    27194400  \n",
      "3    41381500  \n",
      "4    29003900  \n",
      "..        ...  \n",
      "245  26514600  \n",
      "246  16780300  \n",
      "247  19628600  \n",
      "248  16045700  \n",
      "249  18727200  \n",
      "\n",
      "[250 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf  # for ingesting data from Yahoo Finance\n",
    "import sqlite3  # for ingesting data from SQL\n",
    "\n",
    "def ingest_ohlc_data(data_source):\n",
    "    if data_source == \"CSV\":\n",
    "        df = pd.read_csv(r\"C:\\Users\\Hp\\OneDrive\\Desktop\\Assignment\\GOOGL_ohlc_data.csv\")\n",
    "\n",
    "    elif data_source == \"JSON\":\n",
    "        # Get symbol OHLC data\n",
    "        df = yf.download(\"CL=F\")\n",
    "\n",
    "    elif data_source == \"SQL\":\n",
    "        engine = sqlite3.connect(\"stock_data.db\")\n",
    "        df = pd.read_sql(\"SELECT * FROM ohlc_data\", engine)\n",
    "\n",
    "    data_check(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def data_check(data):\n",
    "    \n",
    "    assert not data.empty, \"DataFrame is empty. Please check the data source.\"\n",
    "\n",
    "    num_missing_values = data.isna().sum().sum()\n",
    "    assert num_missing_values == 0, f\"There are {num_missing_values} missing values in the data.\"\n",
    "\n",
    "    assert data[\"Open\"].dtype == np.float64, \"Data type for Open needs to be float64.\"\n",
    "    assert data[\"High\"].dtype == np.float64, \"Data type for High needs to be float64.\"\n",
    "    assert data[\"Low\"].dtype == np.float64, \"Data type for Low needs to be float64.\"\n",
    "    assert data[\"Close\"].dtype == np.float64, \"Data type for Close needs to be float64.\"\n",
    "\n",
    "    print(\"Data integrity is valid. No missing values or type inconsistencies detected.\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "df = ingest_ohlc_data(\"CSV\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f48837-2c30-4717-9920-7edac66be4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2023-01-03  89.589996  91.050003  88.519997  89.120003  89.120003  28131200\n",
      "1  2023-01-04  90.349998  90.650002  87.269997  88.080002  88.080002  34854800\n",
      "2  2023-01-05  87.470001  87.570000  85.900002  86.199997  86.199997  27194400\n",
      "3  2023-01-06  86.790001  87.690002  84.860001  87.339996  87.339996  41381500\n",
      "4  2023-01-09  88.360001  90.050003  87.860001  88.019997  88.019997  29003900\n",
      "\n",
      "After cleaning:\n",
      "        Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0 2023-01-03  89.589996  91.050003  88.519997  89.120003  89.120003  28131200\n",
      "1 2023-01-04  90.349998  90.650002  87.269997  88.080002  88.080002  34854800\n",
      "2 2023-01-05  87.470001  87.570000  85.900002  86.199997  86.199997  27194400\n",
      "3 2023-01-06  86.790001  87.690002  84.860001  87.339996  87.339996  41381500\n",
      "4 2023-01-09  88.360001  90.050003  87.860001  88.019997  88.019997  29003900\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def outlier_handling(df, column_with_outliers):\n",
    "    q1 = df[column_with_outliers].quantile(0.25)\n",
    "    q3 = df[column_with_outliers].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    # Remove outliers\n",
    "    df = df[(df[column_with_outliers] > (q1 - 1.5 * iqr)) & (df[column_with_outliers] < (q3 + 1.5 * iqr))]\n",
    "    return df\n",
    "\n",
    "def date_formatting(df, column_with_date):\n",
    "    # format date column\n",
    "    df[column_with_date] = pd.to_datetime(df[column_with_date], format='%Y-%m-%d')\n",
    "    return df\n",
    "\n",
    "def remove_missing_values(df):\n",
    "    # Remove rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def ohlc_data_cleaning_pipeline(df_path, column_with_outliers, column_with_date):\n",
    "    df = pd.read_csv(df_path)\n",
    "    print('Before cleaning:')\n",
    "    print(df.head())\n",
    "    \n",
    "    df_no_outliers = outlier_handling(df, column_with_outliers)\n",
    "    df_date_formatted = date_formatting(df_no_outliers, column_with_date)\n",
    "    clean_df = remove_missing_values(df_date_formatted)\n",
    "    \n",
    "    print('\\nAfter cleaning:')\n",
    "    print(clean_df.head())\n",
    "    \n",
    "    return clean_df\n",
    "\n",
    "clean_df = ohlc_data_cleaning_pipeline(r\"C:\\Users\\Hp\\OneDrive\\Desktop\\Assignment\\GOOGL_ohlc_data.csv\", 'Close', 'Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4178f153-1cd3-4777-850b-fb87c99832f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date        Open        High         Low       Close   Adj Close  \\\n",
      "0    2023-01-03   89.589996   91.050003   88.519997   89.120003   89.120003   \n",
      "1    2023-01-04   90.349998   90.650002   87.269997   88.080002   88.080002   \n",
      "2    2023-01-05   87.470001   87.570000   85.900002   86.199997   86.199997   \n",
      "3    2023-01-06   86.790001   87.690002   84.860001   87.339996   87.339996   \n",
      "4    2023-01-09   88.360001   90.050003   87.860001   88.019997   88.019997   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "245  2023-12-22  140.770004  141.990005  140.710007  141.490005  141.490005   \n",
      "246  2023-12-26  141.589996  142.679993  141.190002  141.520004  141.520004   \n",
      "247  2023-12-27  141.589996  142.080002  139.889999  140.369995  140.369995   \n",
      "248  2023-12-28  140.779999  141.139999  139.750000  140.229996  140.229996   \n",
      "249  2023-12-29  139.630005  140.360001  138.779999  139.690002  139.690002   \n",
      "\n",
      "       Volume      SMA_20    Upper_BB    Lower_BB     RSI_14  \n",
      "0    28131200         NaN         NaN         NaN        NaN  \n",
      "1    34854800         NaN         NaN         NaN        NaN  \n",
      "2    27194400         NaN         NaN         NaN        NaN  \n",
      "3    41381500         NaN         NaN         NaN        NaN  \n",
      "4    29003900         NaN         NaN         NaN        NaN  \n",
      "..        ...         ...         ...         ...        ...  \n",
      "245  26514600  134.540501  141.223106  127.857897  75.206283  \n",
      "246  16780300  134.796001  142.137800  127.454203  73.348125  \n",
      "247  19628600  134.954501  142.643486  127.265517  72.767252  \n",
      "248  16045700  135.216501  143.259530  127.173472  60.338351  \n",
      "249  18727200  135.574501  143.750340  127.398662  66.140085  \n",
      "\n",
      "[250 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_sma(data, window=20):\n",
    "  \n",
    "    return data['Close'].rolling(window=window).mean()\n",
    "\n",
    "def calculate_bollinger_bands(data, window=20, num_std=2):\n",
    "    \n",
    "    sma = data['Close'].rolling(window=window).mean()\n",
    "    std = data['Close'].rolling(window=window).std()\n",
    "    upper_band = sma + (num_std * std)\n",
    "    lower_band = sma - (num_std * std)\n",
    "    return upper_band, lower_band\n",
    "\n",
    "def calculate_rsi(data, window=14):\n",
    "    \n",
    "    delta = data['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "\n",
    "# Calculate SMA with a window of 20 days\n",
    "df['SMA_20'] = calculate_sma(df, window=20)\n",
    "\n",
    "# Calculate Bollinger Bands with a window of 20 days and 2 standard deviations\n",
    "upper_band, lower_band = calculate_bollinger_bands(df, window=20, num_std=2)\n",
    "df['Upper_BB'] = upper_band\n",
    "df['Lower_BB'] = lower_band\n",
    "\n",
    "# Calculate RSI with a window of 14 days\n",
    "df['RSI_14'] = calculate_rsi(df, window=14)\n",
    "\n",
    "# Print DataFrame with calculated indicators\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6060f615-eeba-404b-92b2-37c208f1f30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date        Open        High         Low       Close   Adj Close  \\\n",
      "0    2023-01-03   89.589996   91.050003   88.519997   89.120003   89.120003   \n",
      "1    2023-01-04   90.349998   90.650002   87.269997   88.080002   88.080002   \n",
      "2    2023-01-05   87.470001   87.570000   85.900002   86.199997   86.199997   \n",
      "3    2023-01-06   86.790001   87.690002   84.860001   87.339996   87.339996   \n",
      "4    2023-01-09   88.360001   90.050003   87.860001   88.019997   88.019997   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "245  2023-12-22  140.770004  141.990005  140.710007  141.490005  141.490005   \n",
      "246  2023-12-26  141.589996  142.679993  141.190002  141.520004  141.520004   \n",
      "247  2023-12-27  141.589996  142.080002  139.889999  140.369995  140.369995   \n",
      "248  2023-12-28  140.779999  141.139999  139.750000  140.229996  140.229996   \n",
      "249  2023-12-29  139.630005  140.360001  138.779999  139.690002  139.690002   \n",
      "\n",
      "       Volume      SMA_20    Upper_BB    Lower_BB     RSI_14   Std_Dev  \\\n",
      "0    28131200         NaN         NaN         NaN        NaN       NaN   \n",
      "1    34854800         NaN         NaN         NaN        NaN       NaN   \n",
      "2    27194400         NaN         NaN         NaN        NaN       NaN   \n",
      "3    41381500         NaN         NaN         NaN        NaN       NaN   \n",
      "4    29003900         NaN         NaN         NaN        NaN       NaN   \n",
      "..        ...         ...         ...         ...        ...       ...   \n",
      "245  26514600  134.540501  141.223106  127.857897  75.206283  3.341302   \n",
      "246  16780300  134.796001  142.137800  127.454203  73.348125  3.670899   \n",
      "247  19628600  134.954501  142.643486  127.265517  72.767252  3.844492   \n",
      "248  16045700  135.216501  143.259530  127.173472  60.338351  4.021514   \n",
      "249  18727200  135.574501  143.750340  127.398662  66.140085  4.087919   \n",
      "\n",
      "          ATR   EMA_short    EMA_long      MACD  Signal_line       EMA_9  \n",
      "0         NaN   89.120003   89.120003  0.000000     0.000000   89.120003  \n",
      "1         NaN   88.556669   88.580002 -0.023333    -0.012963   88.542224  \n",
      "2         NaN   87.636859   87.724889 -0.088030    -0.043728   87.582295  \n",
      "3         NaN   87.543151   87.617290 -0.074139    -0.054030   87.500216  \n",
      "4         NaN   87.672708   87.710679 -0.037971    -0.049253   87.654839  \n",
      "..        ...         ...         ...       ...          ...         ...  \n",
      "245  3.219500  136.427576  134.977291  1.450285     0.586783  137.131553  \n",
      "246  3.172999  137.211026  135.461936  1.749090     0.819245  138.009243  \n",
      "247  3.190999  137.697021  135.825496  1.871525     1.029701  138.481393  \n",
      "248  3.087999  138.086710  136.151755  1.934955     1.210752  138.831114  \n",
      "249  2.953499  138.333370  136.413848  1.919523     1.352506  139.002892  \n",
      "\n",
      "[250 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_volatility_measures(data, window=20):\n",
    "    \"\"\"\n",
    "    Calculate volatility measures such as standard deviation and ATR.\n",
    "    \"\"\"\n",
    "    # Standard Deviation\n",
    "    data['Std_Dev'] = data['Close'].rolling(window=window).std()\n",
    "\n",
    "    # Average True Range (ATR)\n",
    "    high_low_range = data['High'] - data['Low']\n",
    "    high_close_range = np.abs(data['High'] - data['Close'].shift())\n",
    "    low_close_range = np.abs(data['Low'] - data['Close'].shift())\n",
    "    true_range = pd.concat([high_low_range, high_close_range, low_close_range], axis=1).max(axis=1)\n",
    "    data['ATR'] = true_range.rolling(window=window).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "def calculate_price_patterns(data, short_window=12, long_window=26, signal_window=9):\n",
    "    \"\"\"\n",
    "    Calculate price patterns such as MACD and EMA.\n",
    "    \"\"\"\n",
    "    # Moving Average Convergence Divergence (MACD)\n",
    "    data['EMA_short'] = data['Close'].ewm(span=short_window, min_periods=1).mean()\n",
    "    data['EMA_long'] = data['Close'].ewm(span=long_window, min_periods=1).mean()\n",
    "    data['MACD'] = data['EMA_short'] - data['EMA_long']\n",
    "    data['Signal_line'] = data['MACD'].ewm(span=signal_window, min_periods=1).mean()\n",
    "\n",
    "    # Exponential Moving Average (EMA)\n",
    "    data['EMA_9'] = data['Close'].ewm(span=9, min_periods=1).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "# Calculate volatility measures\n",
    "df = calculate_volatility_measures(df)\n",
    "\n",
    "# Calculate price patterns\n",
    "df = calculate_price_patterns(df)\n",
    "\n",
    "# Print DataFrame with calculated features\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbff74e-50ff-4c36-8615-f7a8bd668745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Open        High         Low       Close    Volume\n",
      "Date                                                                         \n",
      "2023-01-03 00:00:00   89.589996   91.050003   88.519997   89.120003  28131200\n",
      "2023-01-03 01:00:00         NaN         NaN         NaN         NaN         0\n",
      "2023-01-03 02:00:00         NaN         NaN         NaN         NaN         0\n",
      "2023-01-03 03:00:00         NaN         NaN         NaN         NaN         0\n",
      "2023-01-03 04:00:00         NaN         NaN         NaN         NaN         0\n",
      "...                         ...         ...         ...         ...       ...\n",
      "2023-12-28 20:00:00         NaN         NaN         NaN         NaN         0\n",
      "2023-12-28 21:00:00         NaN         NaN         NaN         NaN         0\n",
      "2023-12-28 22:00:00         NaN         NaN         NaN         NaN         0\n",
      "2023-12-28 23:00:00         NaN         NaN         NaN         NaN         0\n",
      "2023-12-29 00:00:00  139.630005  140.360001  138.779999  139.690002  18727200\n",
      "\n",
      "[8641 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def resample_ohlc_data(data, frequency='H'):\n",
    "    \"\"\"\n",
    "    Resample OHLC data based on desired frequency.\n",
    "    \"\"\"\n",
    "    # Set the 'Date' column as the index\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data.set_index('Date', inplace=True)\n",
    "\n",
    "    # Resample OHLC data\n",
    "    resampled_data = data.resample(frequency).agg({\n",
    "        'Open': 'first',\n",
    "        'High': 'max',\n",
    "        'Low': 'min',\n",
    "        'Close': 'last',\n",
    "        'Volume': 'sum'\n",
    "    })\n",
    "\n",
    "    return resampled_data\n",
    "\n",
    "\n",
    "# Resample OHLC data from daily to hourly frequency\n",
    "hourly_data = resample_ohlc_data(df, frequency='H')\n",
    "\n",
    "# Print resampled DataFrame\n",
    "print(hourly_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0f7ffad-915c-4f21-876e-818e1746aee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_data_check_dtypes (__main__.TestDataCheck) ... ok\n",
      "test_data_check_no_missing_values (__main__.TestDataCheck) ... ok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data integrity is valid. No missing values or type inconsistencies detected.\n",
      "\n",
      "\n",
      "Data integrity is valid. No missing values or type inconsistencies detected.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_data_check_not_empty (__main__.TestDataCheck) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data integrity is valid. No missing values or type inconsistencies detected.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "test_date_formatting (__main__.TestDataCleaningPipeline) ... ok\n",
      "test_outlier_handling (__main__.TestDataCleaningPipeline) ... ok\n",
      "test_remove_missing_values (__main__.TestDataCleaningPipeline) ... ok\n",
      "test_csv_ingestion (__main__.TestDataIngestion) ... ok\n",
      "test_correct_outliers (__main__.TestDataPipeline) ... ok\n",
      "test_detect_outliers_iqr (__main__.TestDataPipeline) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 0.879s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x19a57ccc8b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf  # for ingesting data from Yahoo Finance\n",
    "import sqlite3  # for ingesting data from SQL\n",
    "import unittest\n",
    "\n",
    "def ingest_ohlc_data(data_source):\n",
    "    if data_source == \"CSV\":\n",
    "        df = pd.read_csv(r\"C:\\Users\\Hp\\OneDrive\\Desktop\\Assignment\\GOOGL_ohlc_data.csv\")\n",
    "\n",
    "    elif data_source == \"JSON\":\n",
    "        # Get symbol OHLC data\n",
    "        df = yf.download(\"CL=F\")\n",
    "\n",
    "    elif data_source == \"SQL\":\n",
    "        engine = sqlite3.connect(\"stock_data.db\")\n",
    "        df = pd.read_sql(\"SELECT * FROM ohlc_data\", engine)\n",
    "\n",
    "    return df\n",
    "\n",
    "class TestDataIngestion(unittest.TestCase):\n",
    "\n",
    "    def test_csv_ingestion(self):\n",
    "        df = ingest_ohlc_data(\"CSV\")\n",
    "        self.assertIsNotNone(df)\n",
    "        self.assertIsInstance(df, pd.DataFrame)\n",
    "\n",
    "    # Add more tests for JSON and SQL ingestion if needed\n",
    "\n",
    "class TestDataCheck(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.df = pd.read_csv(r\"C:\\Users\\Hp\\OneDrive\\Desktop\\Assignment\\GOOGL_ohlc_data.csv\")\n",
    "\n",
    "    def test_data_check_not_empty(self):\n",
    "        data_check(self.df)\n",
    "        self.assertFalse(self.df.empty)\n",
    "\n",
    "    def test_data_check_no_missing_values(self):\n",
    "        data_check(self.df)\n",
    "        self.assertEqual(self.df.isna().sum().sum(), 0)\n",
    "\n",
    "    def test_data_check_dtypes(self):\n",
    "        data_check(self.df)\n",
    "        self.assertEqual(self.df[\"Open\"].dtype, np.float64)\n",
    "        self.assertEqual(self.df[\"High\"].dtype, np.float64)\n",
    "        self.assertEqual(self.df[\"Low\"].dtype, np.float64)\n",
    "        self.assertEqual(self.df[\"Close\"].dtype, np.float64)\n",
    "\n",
    "def outlier_handling(df, column_with_outliers):\n",
    "    q1 = df[column_with_outliers].quantile(0.25)\n",
    "    q3 = df[column_with_outliers].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    # Remove outliers\n",
    "    df = df[(df[column_with_outliers] > (q1 - 1.5 * iqr)) & (df[column_with_outliers] < (q3 + 1.5 * iqr))]\n",
    "    return df\n",
    "\n",
    "def date_formatting(df, column_with_date):\n",
    "    # format date column\n",
    "    df[column_with_date] = pd.to_datetime(df[column_with_date], format='%Y-%m-%d')\n",
    "    return df\n",
    "\n",
    "def remove_missing_values(df):\n",
    "    # Remove rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "class TestDataCleaningPipeline(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.df = pd.read_csv(r\"C:\\Users\\Hp\\OneDrive\\Desktop\\Assignment\\GOOGL_ohlc_data.csv\")\n",
    "\n",
    "    def test_outlier_handling(self):\n",
    "        df_cleaned = outlier_handling(self.df, 'Close')\n",
    "        self.assertEqual(len(self.df), len(df_cleaned))\n",
    "\n",
    "    def test_date_formatting(self):\n",
    "        df_formatted = date_formatting(self.df, 'Date')\n",
    "        self.assertTrue(isinstance(df_formatted['Date'].iloc[0], pd.Timestamp))\n",
    "\n",
    "    def test_remove_missing_values(self):\n",
    "        df_no_missing = remove_missing_values(self.df)\n",
    "        self.assertEqual(len(df_no_missing), len(self.df) - self.df.isna().sum().sum())\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f8770f-c11a-42da-85d6-f0b190f8bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data integrity check passed.\n",
      "INFO:root:Data ingestion successful.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def ingest_ohlc_data(data_source):\n",
    "    try:\n",
    "        if data_source == \"CSV\":\n",
    "            df = pd.read_csv(r\"C:\\Users\\Hp\\OneDrive\\Desktop\\Assignment\\GOOGL_ohlc_data.csv\")\n",
    "        elif data_source == \"JSON\":\n",
    "            # Get symbol OHLC data\n",
    "            df = yf.download(\"CL=F\")\n",
    "        elif data_source == \"SQL\":\n",
    "            engine = sqlite3.connect(\"stock_data.db\")\n",
    "            df = pd.read_sql(\"SELECT * FROM ohlc_data\", engine)\n",
    "\n",
    "        data_check(df)\n",
    "        logging.info(\"Data ingestion successful.\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error during data ingestion: %s\", e)\n",
    "        raise\n",
    "\n",
    "def data_check(data):\n",
    "    try:\n",
    "        assert not data.empty, \"DataFrame is empty. Please check the data source.\"\n",
    "        num_missing_values = data.isna().sum().sum()\n",
    "        assert num_missing_values == 0, f\"There are {num_missing_values} missing values in the data.\"\n",
    "        assert data[\"Open\"].dtype == np.float64, \"Data type for Open needs to be float64.\"\n",
    "        assert data[\"High\"].dtype == np.float64, \"Data type for High needs to be float64.\"\n",
    "        assert data[\"Low\"].dtype == np.float64, \"Data type for Low needs to be float64.\"\n",
    "        assert data[\"Close\"].dtype == np.float64, \"Data type for Close needs to be float64.\"\n",
    "        logging.info(\"Data integrity check passed.\")\n",
    "\n",
    "    except AssertionError as ae:\n",
    "        logging.warning(\"Data quality issue: %s\", ae)\n",
    "        raise\n",
    "\n",
    "\n",
    "try:\n",
    "    df = ingest_ohlc_data(\"CSV\")\n",
    "except Exception as e:\n",
    "    logging.error(\"Pipeline failed with error: %s\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e1fea72-cea5-4c93-9224-f7dc870d9bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data integrity is valid. No missing values or type inconsistencies detected.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import sqlite3\n",
    "\n",
    "def ingest_ohlc_data(data_source, db_file):\n",
    "    if data_source == \"CSV\":\n",
    "        df = pd.read_csv(r\"C:\\Users\\Hp\\OneDrive\\Desktop\\Assignment\\GOOGL_ohlc_data.csv\")\n",
    "\n",
    "    elif data_source == \"JSON\":\n",
    "        # Get symbol OHLC data\n",
    "        df = yf.download(\"CL=F\")\n",
    "\n",
    "    elif data_source == \"SQL\":\n",
    "        engine = sqlite3.connect(db_file)\n",
    "        df = pd.read_sql(\"SELECT * FROM ohlc_data\", engine)\n",
    "\n",
    "    data_check(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def data_check(data):\n",
    "    assert not data.empty, \"DataFrame is empty. Please check the data source.\"\n",
    "\n",
    "    num_missing_values = data.isna().sum().sum()\n",
    "    assert num_missing_values == 0, f\"There are {num_missing_values} missing values in the data.\"\n",
    "\n",
    "    assert data[\"Open\"].dtype == np.float64, \"Data type for Open needs to be float64.\"\n",
    "    assert data[\"High\"].dtype == np.float64, \"Data type for High needs to be float64.\"\n",
    "    assert data[\"Low\"].dtype == np.float64, \"Data type for Low needs to be float64.\"\n",
    "    assert data[\"Close\"].dtype == np.float64, \"Data type for Close needs to be float64.\"\n",
    "\n",
    "    print(\"Data integrity is valid. No missing values or type inconsistencies detected.\")\n",
    "\n",
    "def save_to_sqlite(data, db_file, table_name='ohlc_data'):\n",
    "    engine = sqlite3.connect(db_file)\n",
    "    data.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "# Example usage\n",
    "db_file = 'ohlc_data.db'\n",
    "df = ingest_ohlc_data(\"CSV\", db_file)\n",
    "save_to_sqlite(df, db_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9912c527-cd64-4879-a4e6-f15d2d102172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2023, Month: 1\n",
      "        Date       Open       High        Low      Close  Adj Close    Volume  \\\n",
      "0 2023-01-03  89.589996  91.050003  88.519997  89.120003  89.120003  28131200   \n",
      "1 2023-01-04  90.349998  90.650002  87.269997  88.080002  88.080002  34854800   \n",
      "2 2023-01-05  87.470001  87.570000  85.900002  86.199997  86.199997  27194400   \n",
      "3 2023-01-06  86.790001  87.690002  84.860001  87.339996  87.339996  41381500   \n",
      "4 2023-01-09  88.360001  90.050003  87.860001  88.019997  88.019997  29003900   \n",
      "\n",
      "   Year  Month  \n",
      "0  2023      1  \n",
      "1  2023      1  \n",
      "2  2023      1  \n",
      "3  2023      1  \n",
      "4  2023      1  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 2\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "20 2023-02-01   98.709999  101.190002   97.580002  100.430000  100.430000   \n",
      "21 2023-02-02  105.800003  107.849998  105.610001  107.739998  107.739998   \n",
      "22 2023-02-03  102.930000  107.809998  102.580002  104.779999  104.779999   \n",
      "23 2023-02-06  102.400002  104.360001  101.879997  102.900002  102.900002   \n",
      "24 2023-02-07  103.220001  108.180000  103.120003  107.639999  107.639999   \n",
      "\n",
      "      Volume  Year  Month  \n",
      "20  35531100  2023      2  \n",
      "21  69883800  2023      2  \n",
      "22  65309300  2023      2  \n",
      "23  31999600  2023      2  \n",
      "24  49010200  2023      2  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 3\n",
      "         Date       Open       High        Low      Close  Adj Close  \\\n",
      "39 2023-03-01  89.980003  91.029999  89.669998  90.360001  90.360001   \n",
      "40 2023-03-02  89.660004  92.279999  89.589996  92.000000  92.000000   \n",
      "41 2023-03-03  92.480003  93.730003  92.449997  93.650002  93.650002   \n",
      "42 2023-03-06  94.019997  95.970001  94.000000  95.129997  95.129997   \n",
      "43 2023-03-07  94.980003  95.669998  93.529999  93.860001  93.860001   \n",
      "\n",
      "      Volume  Year  Month  \n",
      "39  31111200  2023      3  \n",
      "40  32204400  2023      3  \n",
      "41  35160100  2023      3  \n",
      "42  32639300  2023      3  \n",
      "43  27835500  2023      3  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 4\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "62 2023-04-03  102.389999  104.529999  101.930000  104.360001  104.360001   \n",
      "63 2023-04-04  104.330002  105.580002  104.040001  104.720001  104.720001   \n",
      "64 2023-04-05  105.779999  106.099998  103.660004  104.470001  104.470001   \n",
      "65 2023-04-06  105.260002  109.169998  104.330002  108.419998  108.419998   \n",
      "66 2023-04-10  106.980003  107.589996  105.120003  106.440002  106.440002   \n",
      "\n",
      "      Volume  Year  Month  \n",
      "62  25035400  2023      4  \n",
      "63  24420100  2023      4  \n",
      "64  28290500  2023      4  \n",
      "65  48711500  2023      4  \n",
      "66  27067400  2023      4  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 5\n",
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "81 2023-05-01  106.839996  107.989998  106.820000  107.199997  107.199997   \n",
      "82 2023-05-02  107.139999  107.199997  103.709999  105.320000  105.320000   \n",
      "83 2023-05-03  105.529999  107.489998  104.959999  105.410004  105.410004   \n",
      "84 2023-05-04  105.489998  105.599998  103.970001  104.690002  104.690002   \n",
      "85 2023-05-05  104.820000  105.879997  104.110001  105.570000  105.570000   \n",
      "\n",
      "      Volume  Year  Month  \n",
      "81  26681700  2023      5  \n",
      "82  30997200  2023      5  \n",
      "83  21795400  2023      5  \n",
      "84  23419500  2023      5  \n",
      "85  26625100  2023      5  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 6\n",
      "          Date        Open        High         Low       Close   Adj Close  \\\n",
      "103 2023-06-01  122.820000  124.419998  122.620003  123.720001  123.720001   \n",
      "104 2023-06-02  123.989998  126.150002  123.760002  124.669998  124.669998   \n",
      "105 2023-06-05  124.010002  127.430000  123.839996  126.010002  126.010002   \n",
      "106 2023-06-06  126.010002  128.289993  125.360001  127.309998  127.309998   \n",
      "107 2023-06-07  126.970001  129.039993  122.120003  122.500000  122.500000   \n",
      "\n",
      "       Volume  Year  Month  \n",
      "103  30772700  2023      6  \n",
      "104  26963100  2023      6  \n",
      "105  32305500  2023      6  \n",
      "106  26638300  2023      6  \n",
      "107  52539000  2023      6  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 7\n",
      "          Date        Open        High         Low       Close   Adj Close  \\\n",
      "124 2023-07-03  119.239998  120.190002  118.820000  119.900002  119.900002   \n",
      "125 2023-07-05  119.239998  122.610001  119.230003  121.750000  121.750000   \n",
      "126 2023-07-06  119.800003  120.300003  118.400002  120.110001  120.110001   \n",
      "127 2023-07-07  120.099998  121.050003  119.400002  119.480003  119.480003   \n",
      "128 2023-07-10  118.300003  118.309998  116.139999  116.449997  116.449997   \n",
      "\n",
      "       Volume  Year  Month  \n",
      "124  14467900  2023      7  \n",
      "125  27584800  2023      7  \n",
      "126  24745200  2023      7  \n",
      "127  21692600  2023      7  \n",
      "128  35315200  2023      7  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 8\n",
      "          Date        Open        High         Low       Close   Adj Close  \\\n",
      "144 2023-08-01  130.779999  132.630005  130.679993  131.550003  131.550003   \n",
      "145 2023-08-02  129.449997  130.089996  127.559998  128.380005  128.380005   \n",
      "146 2023-08-03  127.970001  129.389999  127.419998  128.449997  128.449997   \n",
      "147 2023-08-04  129.279999  131.509995  127.910004  128.110001  128.110001   \n",
      "148 2023-08-07  129.160004  131.610001  129.020004  131.529999  131.529999   \n",
      "\n",
      "       Volume  Year  Month  \n",
      "144  23166800  2023      8  \n",
      "145  26273300  2023      8  \n",
      "146  20089500  2023      8  \n",
      "147  26130000  2023      8  \n",
      "148  22746300  2023      8  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 9\n",
      "          Date        Open        High         Low       Close   Adj Close  \\\n",
      "167 2023-09-01  137.460007  137.460007  134.850006  135.660004  135.660004   \n",
      "168 2023-09-05  135.440002  136.419998  134.580002  135.770004  135.770004   \n",
      "169 2023-09-06  136.020004  136.529999  133.669998  134.460007  134.460007   \n",
      "170 2023-09-07  133.589996  135.580002  132.949997  135.259995  135.259995   \n",
      "171 2023-09-08  134.910004  136.660004  134.850006  136.380005  136.380005   \n",
      "\n",
      "       Volume  Year  Month  \n",
      "167  21524600  2023      9  \n",
      "168  19403100  2023      9  \n",
      "169  18684500  2023      9  \n",
      "170  18844300  2023      9  \n",
      "171  23558300  2023      9  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 10\n",
      "          Date        Open        High         Low       Close   Adj Close  \\\n",
      "187 2023-10-02  131.210007  134.419998  131.169998  134.169998  134.169998   \n",
      "188 2023-10-03  133.940002  134.259995  131.839996  132.429993  132.429993   \n",
      "189 2023-10-04  132.789993  135.570007  132.529999  135.240005  135.240005   \n",
      "190 2023-10-05  135.070007  135.490005  133.449997  135.070007  135.070007   \n",
      "191 2023-10-06  134.009995  138.160004  134.009995  137.580002  137.580002   \n",
      "\n",
      "       Volume  Year  Month  \n",
      "187  22288000  2023     10  \n",
      "188  22989400  2023     10  \n",
      "189  26752300  2023     10  \n",
      "190  19832600  2023     10  \n",
      "191  27583200  2023     10  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 11\n",
      "          Date        Open        High         Low       Close   Adj Close  \\\n",
      "209 2023-11-01  124.070000  126.489998  123.720001  126.449997  126.449997   \n",
      "210 2023-11-02  128.419998  128.979996  126.930000  127.489998  127.489998   \n",
      "211 2023-11-03  128.020004  129.529999  127.860001  129.100006  129.100006   \n",
      "212 2023-11-06  129.050003  130.339996  128.669998  130.250000  130.250000   \n",
      "213 2023-11-07  130.710007  131.910004  129.880005  130.970001  130.970001   \n",
      "\n",
      "       Volume  Year  Month  \n",
      "209  30082400  2023     11  \n",
      "210  27124600  2023     11  \n",
      "211  26380100  2023     11  \n",
      "212  19052700  2023     11  \n",
      "213  29757300  2023     11  \n",
      "\n",
      "\n",
      "Year: 2023, Month: 12\n",
      "          Date        Open        High         Low       Close   Adj Close  \\\n",
      "230 2023-12-01  131.860001  132.110001  130.669998  131.860001  131.860001   \n",
      "231 2023-12-04  129.880005  130.029999  127.900002  129.270004  129.270004   \n",
      "232 2023-12-05  128.949997  132.139999  128.250000  130.990005  130.990005   \n",
      "233 2023-12-06  131.440002  131.839996  129.880005  130.020004  130.020004   \n",
      "234 2023-12-07  135.039993  138.559998  134.699997  136.929993  136.929993   \n",
      "\n",
      "       Volume  Year  Month  \n",
      "230  31431200  2023     12  \n",
      "231  36669900  2023     12  \n",
      "232  27384800  2023     12  \n",
      "233  23576200  2023     12  \n",
      "234  56767100  2023     12  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def partition_data(data):\n",
    "    \n",
    "    # Convert the 'Date' column to datetime if it's not already in datetime format\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "    # Extract year and month from the 'Date' column\n",
    "    data['Year'] = data['Date'].dt.year\n",
    "    data['Month'] = data['Date'].dt.month\n",
    "\n",
    "    # Group the data by year and month\n",
    "    grouped_data = data.groupby(['Year', 'Month'])\n",
    "\n",
    "    return grouped_data\n",
    "\n",
    "# Partition the data\n",
    "partitioned_data = partition_data(df)\n",
    "\n",
    "# Iterate over each partition and print the first few rows\n",
    "for (year, month), partition in partitioned_data:\n",
    "    print(f\"Year: {year}, Month: {month}\")\n",
    "    print(partition.head())\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f28a8552-f38b-4912-8d91-eeb14c0540cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date        Open        High         Low       Close   Adj Close  \\\n",
      "0   2023-01-03   89.589996   91.050003   88.519997   89.120003   89.120003   \n",
      "1   2023-01-04   90.349998   90.650002   87.269997   88.080002   88.080002   \n",
      "2   2023-01-05   87.470001   87.570000   85.900002   86.199997   86.199997   \n",
      "3   2023-01-06   86.790001   87.690002   84.860001   87.339996   87.339996   \n",
      "4   2023-01-09   88.360001   90.050003   87.860001   88.019997   88.019997   \n",
      "..         ...         ...         ...         ...         ...         ...   \n",
      "245 2023-12-22  140.770004  141.990005  140.710007  141.490005  141.490005   \n",
      "246 2023-12-26  141.589996  142.679993  141.190002  141.520004  141.520004   \n",
      "247 2023-12-27  141.589996  142.080002  139.889999  140.369995  140.369995   \n",
      "248 2023-12-28  140.779999  141.139999  139.750000  140.229996  140.229996   \n",
      "249 2023-12-29  139.630005  140.360001  138.779999  139.690002  139.690002   \n",
      "\n",
      "       Volume  Year  Month  \n",
      "0    28131200  2023      1  \n",
      "1    34854800  2023      1  \n",
      "2    27194400  2023      1  \n",
      "3    41381500  2023      1  \n",
      "4    29003900  2023      1  \n",
      "..        ...   ...    ...  \n",
      "245  26514600  2023     12  \n",
      "246  16780300  2023     12  \n",
      "247  19628600  2023     12  \n",
      "248  16045700  2023     12  \n",
      "249  18727200  2023     12  \n",
      "\n",
      "[250 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert DataFrame to Parquet format\n",
    "df.to_parquet('ohlc_data.parquet', compression='snappy')\n",
    "\n",
    "# Read Parquet file\n",
    "parquet_data = pd.read_parquet('ohlc_data.parquet')\n",
    "\n",
    "# Print DataFrame from Parquet file\n",
    "print(parquet_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
